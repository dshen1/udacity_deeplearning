{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "In the previous post, we saw how to do Image Classification by performing crop of the central part of an image and making an inference using one of the standart classification models. After that, we saw how to perform the network inference on the whole image by changing the network to fully convolutional one. This approach gave us a downsampled prediction map for the image -- that happened due to the fact that max-pooling layers are used in the network architecture. This prediction map can be treated as an efficient way to make an inference of the network for the whole image. You can also think about it as a way to make Image Segmentation, but it is not an actual Segmentation, because the standart network models were trained to perform Classification. To make it perform an actual Segmentation, we will have to train it on Segmentation dataset in a special way like in the paper Fully convolutional networks for semantic segmentation by Long et al. Two of the most popular general Segmentation datasets are: Microsoft COCO and PASCAL VOC.\n",
    "\n",
    "In this post, we will perform image upsampling to get the prediction map that is of the same size as an input image. We will do this using transposed convolution (also known as deconvolution). It is recommended not to use the deconvolution name for this operation as it can be confused with another operation and it does not represent accurately the actual process that is being performed. The most accurate name for the kind of operation that we will perform in this post is fractionally strided convolution. We will cover a small part of theory necessary for understanding and some resources will be cited.\n",
    "\n",
    "One question might be raised up now: Why do we need to perform upsampling using fractionally strided convolution? Why can't we just use some library to do this for us? The answer is: we need to do this because we need to define the upsampling operation as a layer in the network. And why do we need it as a layer? Because we will have to perform training where the image and respective Segmentation groundtruth will be given to us -- and we will have to perform training using backpropagation. As it is known , each layer in the network has to be able to perform three operations: forward propagation, backward propagation and update which performs updates to the weights of the layer during training. By doing the upsampling with transposed convolution we will have all of these operations defined and we will be able to perform training.\n",
    "\n",
    "By the end of the post, we will implement the upsampling and will make sure it is correct by comparing it to the implementation of the scikit-image library. To be more specific we will have FCN-32 Segmentation network implemented which is described in the paper Fully convolutional networks for semantic segmentation. To perform the training, the loss function has to be defined and training dataset provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import tensorflow.contrib.slim as slim\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "sys.path.append(\"/home/ubuntu/workspace/models/slim\")\n",
    "from datasets import dataset_utils\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\"\n",
    "checkpoints_dir = './checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa247a60940>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAAEYCAYAAAAEStC3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa28842b278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import ogrid, repeat, newaxis\n",
    "from skimage import io\n",
    "\n",
    "# Generate image that will be used for test upsampling\n",
    "# Number of channels is 3 -- we also treat the number of\n",
    "# samples like the number of classes, because later on\n",
    "# that will be used to upsample predictions from the network\n",
    "imsize = 3\n",
    "x, y = ogrid[:imsize, :imsize]\n",
    "img = repeat((x + y)[..., newaxis], 3, 2) / float(imsize + imsize)\n",
    "io.imshow(img, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa239d9f3c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAEYCAYAAABycGI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa247ab87b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skimage.transform\n",
    "\n",
    "def upsample_skimage(factor, input_img):    \n",
    "    # Pad with 0 values, similar to how Tensorflow does it.\n",
    "    # Order=1 is bilinear upsampling\n",
    "    return skimage.transform.rescale(input_img,\n",
    "                                     factor,\n",
    "                                     mode='constant',\n",
    "                                     cval=0,\n",
    "                                     order=1)\n",
    "\n",
    "\n",
    "upsampled_img_skimage = upsample_skimage(factor=3, input_img=img)\n",
    "io.imshow(upsampled_img_skimage, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_img_skimage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
