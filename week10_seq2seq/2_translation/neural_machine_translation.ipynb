{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "X, Y, en_word2idx, en_idx2word, en_vocab, de_word2idx, de_idx2word, de_vocab = read_dataset('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence in English - encoded: [5, 385, 5, 69]\n",
      "Sentence in German - encoded: [7, 690, 8, 59]\n",
      "Decoded:\n",
      "------------------------\n",
      " I hope I got\n",
      " Ich hoffe ich habe\n"
     ]
    }
   ],
   "source": [
    "# inspect data\n",
    "print ('Sentence in English - encoded:', X[2])\n",
    "print ('Sentence in German - encoded:', Y[2])\n",
    "print ('Decoded:\\n------------------------')\n",
    "\n",
    "s=\"\"\n",
    "for i in range(len(X[2])):\n",
    "    s = s + \" \" + en_idx2word[X[2][i]]\n",
    "print(s)\n",
    "\n",
    "s=\"\"\n",
    "for i in range(len(Y[2])):\n",
    "    s = s + \" \" + de_idx2word[Y[2][i]]\n",
    "print (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data padding\n",
    "def data_padding(x, y, length = 15):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i] + (length - len(x[i])) * [en_word2idx['<pad>']]\n",
    "        y[i] = [de_word2idx['<go>']] + y[i] + [de_word2idx['<eos>']] + (length-len(y[i])) * [de_word2idx['<pad>']]\n",
    "\n",
    "data_padding(X, Y)\n",
    "\n",
    "# data splitting\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)\n",
    "\n",
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "\n",
    "input_seq_len = 15\n",
    "output_seq_len = 17\n",
    "en_vocab_size = len(en_vocab) + 2 # + <pad>, <ukn>\n",
    "de_vocab_size = len(de_vocab) + 4 # + <pad>, <ukn>, <eos>, <go>\n",
    "\n",
    "# placeholders\n",
    "encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "targets = [decoder_inputs[i+1] for i in range(output_seq_len-1)]\n",
    "targets.append(tf.placeholder(dtype = tf.int32, shape = [None], name = 'last_target')) ## add last, to make it the same as decode input\n",
    "target_weights = [tf.placeholder(dtype = tf.float32, shape = [None], name = 'target_w{}'.format(i)) for i in range(output_seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output projection\n",
    "size = 512\n",
    "w_t = tf.get_variable('proj_w', [de_vocab_size, size], tf.float32)\n",
    "b = tf.get_variable('proj_b', [de_vocab_size], tf.float32)\n",
    "w = tf.transpose(w_t)\n",
    "output_projection = (w, b)\n",
    "\n",
    "outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                            encoder_inputs,\n",
    "                                            decoder_inputs,\n",
    "                                            tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                            num_encoder_symbols = en_vocab_size,\n",
    "                                            num_decoder_symbols = de_vocab_size,\n",
    "                                            embedding_size = 100,\n",
    "                                            feed_previous = False,\n",
    "                                            output_projection = output_projection,\n",
    "                                            dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our loss function\n",
    "\n",
    "# sampled softmax loss - returns: A batch_size 1-D tensor of per-example sampled softmax losses\n",
    "def sampled_loss(labels, logits):\n",
    "    return tf.nn.sampled_softmax_loss(\n",
    "                        weights = w_t,\n",
    "                        biases = b,\n",
    "                        labels = tf.reshape(labels, [-1, 1]),\n",
    "                        inputs = logits,\n",
    "                        num_sampled = 512,\n",
    "                        num_classes = de_vocab_size)\n",
    "\n",
    "# Weighted cross-entropy loss for a sequence of logits\n",
    "loss = tf.contrib.legacy_seq2seq.sequence_loss(outputs, targets, target_weights, softmax_loss_function = sampled_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define some helper functions\n",
    "\n",
    "# simple softmax function\n",
    "def softmax(x):\n",
    "    n = np.max(x)\n",
    "    e_x = np.exp(x - n)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# feed data into placeholders\n",
    "def feed_dict(x, y, batch_size = 64):\n",
    "    feed = {}\n",
    "    idxes = np.random.choice(len(x), size = batch_size, replace = False)\n",
    "    for i in range(input_seq_len):\n",
    "        feed[encoder_inputs[i].name] = np.array([x[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    for i in range(output_seq_len):\n",
    "        feed[decoder_inputs[i].name] = np.array([y[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    feed[targets[len(targets)-1].name] = np.full(shape = [batch_size], fill_value = de_word2idx['<pad>'], dtype = np.int32)\n",
    "    \n",
    "    for i in range(output_seq_len-1):\n",
    "        batch_weights = np.ones(batch_size, dtype = np.float32)\n",
    "        target = feed[decoder_inputs[i+1].name]\n",
    "        for j in range(batch_size):\n",
    "            if target[j] == de_word2idx['<pad>']:\n",
    "                batch_weights[j] = 0.0\n",
    "        feed[target_weights[i].name] = batch_weights\n",
    "        \n",
    "    feed[target_weights[output_seq_len-1].name] = np.zeros(batch_size, dtype = np.float32)\n",
    "    \n",
    "    return feed\n",
    "\n",
    "# decode output sequence\n",
    "def decode_output(output_seq):\n",
    "    words = []\n",
    "    for i in range(output_seq_len):\n",
    "        smax = softmax(output_seq[i])\n",
    "        idx = np.argmax(smax)\n",
    "        words.append(de_idx2word[idx])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ops and hyperparameters\n",
    "learning_rate = 5e-3\n",
    "batch_size = 64\n",
    "steps = 1000\n",
    "\n",
    "# ops for projecting outputs\n",
    "outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "# training op\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# init op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# forward step\n",
    "def forward_step(sess, feed):\n",
    "    output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "    return output_sequences\n",
    "\n",
    "# training step\n",
    "def backward_step(sess, feed):\n",
    "    sess.run(optimizer, feed_dict = feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TRAINING------------------\n",
      "step: 0, loss: 9.13869571685791\n",
      "step: 4, loss: 9.22422981262207\n",
      "step: 9, loss: 8.960258483886719\n",
      "step: 14, loss: 9.081246376037598\n",
      "step: 19, loss: 8.896175384521484\n",
      "Checkpoint is saved\n",
      "step: 24, loss: 9.050891876220703\n",
      "step: 29, loss: 8.876701354980469\n",
      "step: 34, loss: 8.594988822937012\n",
      "step: 39, loss: 8.134302139282227\n",
      "step: 44, loss: 7.460967063903809\n",
      "step: 49, loss: 7.041047096252441\n",
      "step: 54, loss: 7.156745910644531\n",
      "step: 59, loss: 6.999111652374268\n",
      "step: 64, loss: 6.469021797180176\n",
      "step: 69, loss: 6.178628921508789\n",
      "step: 74, loss: 5.8297576904296875\n",
      "step: 79, loss: 5.673292636871338\n",
      "step: 84, loss: 5.568897247314453\n",
      "step: 89, loss: 5.282375335693359\n",
      "step: 94, loss: 5.640388488769531\n",
      "step: 99, loss: 5.635690689086914\n",
      "step: 104, loss: 5.693165302276611\n",
      "step: 109, loss: 6.255098342895508\n",
      "step: 114, loss: 5.30598258972168\n",
      "step: 119, loss: 5.18610954284668\n",
      "step: 124, loss: 5.18019962310791\n",
      "step: 129, loss: 5.133234024047852\n",
      "step: 134, loss: 5.416015148162842\n",
      "step: 139, loss: 5.478549957275391\n",
      "step: 144, loss: 4.744812965393066\n",
      "step: 149, loss: 5.259202003479004\n",
      "step: 154, loss: 4.89896821975708\n",
      "step: 159, loss: 4.80905818939209\n",
      "step: 164, loss: 5.0576252937316895\n",
      "step: 169, loss: 4.573983669281006\n",
      "step: 174, loss: 4.80239200592041\n",
      "step: 179, loss: 4.47760534286499\n",
      "step: 184, loss: 4.517914772033691\n",
      "step: 189, loss: 4.429405212402344\n",
      "step: 194, loss: 4.4265851974487305\n",
      "step: 199, loss: 3.946556806564331\n",
      "step: 204, loss: 4.927647113800049\n",
      "step: 209, loss: 4.25872802734375\n",
      "step: 214, loss: 4.2698869705200195\n",
      "step: 219, loss: 4.332801818847656\n",
      "Checkpoint is saved\n",
      "step: 224, loss: 4.067214012145996\n",
      "step: 229, loss: 3.6554718017578125\n",
      "step: 234, loss: 3.8966097831726074\n",
      "step: 239, loss: 3.964101791381836\n",
      "step: 244, loss: 4.10562801361084\n",
      "step: 249, loss: 3.9481563568115234\n",
      "step: 254, loss: 3.554828643798828\n",
      "step: 259, loss: 3.8362457752227783\n",
      "step: 264, loss: 3.470283269882202\n",
      "step: 269, loss: 3.302241802215576\n",
      "step: 274, loss: 3.6573009490966797\n",
      "step: 279, loss: 3.387075901031494\n",
      "step: 284, loss: 3.0729057788848877\n",
      "step: 289, loss: 3.3002095222473145\n",
      "step: 294, loss: 3.4623608589172363\n",
      "step: 299, loss: 3.079070568084717\n",
      "step: 304, loss: 3.484196186065674\n",
      "step: 309, loss: 3.3710122108459473\n",
      "step: 314, loss: 3.1452455520629883\n",
      "step: 319, loss: 3.401066780090332\n",
      "step: 324, loss: 2.8840301036834717\n",
      "step: 329, loss: 3.3047873973846436\n",
      "step: 334, loss: 3.1003360748291016\n",
      "step: 339, loss: 2.987440586090088\n",
      "step: 344, loss: 3.0106732845306396\n",
      "step: 349, loss: 3.1062464714050293\n",
      "step: 354, loss: 2.91007137298584\n",
      "step: 359, loss: 2.818678379058838\n",
      "step: 364, loss: 2.817199230194092\n",
      "step: 369, loss: 2.793994426727295\n",
      "step: 374, loss: 2.9105451107025146\n",
      "step: 379, loss: 2.879903554916382\n",
      "step: 384, loss: 2.7787227630615234\n",
      "step: 389, loss: 2.9541587829589844\n",
      "step: 394, loss: 2.7068371772766113\n",
      "step: 399, loss: 2.5851640701293945\n",
      "step: 404, loss: 2.4729621410369873\n",
      "step: 409, loss: 2.5853145122528076\n",
      "step: 414, loss: 2.828521728515625\n",
      "step: 419, loss: 2.697701930999756\n",
      "Checkpoint is saved\n",
      "step: 424, loss: 2.2152867317199707\n",
      "step: 429, loss: 2.51668119430542\n",
      "step: 434, loss: 2.612137794494629\n",
      "step: 439, loss: 2.3788323402404785\n",
      "step: 444, loss: 2.3826797008514404\n",
      "step: 449, loss: 2.1963348388671875\n",
      "step: 454, loss: 2.1780824661254883\n",
      "step: 459, loss: 2.2457756996154785\n",
      "step: 464, loss: 2.6333250999450684\n",
      "step: 469, loss: 2.2818644046783447\n",
      "step: 474, loss: 2.397817850112915\n",
      "step: 479, loss: 2.155841827392578\n",
      "step: 484, loss: 2.1133108139038086\n",
      "step: 489, loss: 2.334521770477295\n",
      "step: 494, loss: 1.7969900369644165\n",
      "step: 499, loss: 2.0050160884857178\n",
      "step: 504, loss: 2.346359968185425\n",
      "step: 509, loss: 1.8020679950714111\n",
      "step: 514, loss: 1.9354357719421387\n",
      "step: 519, loss: 1.8569048643112183\n",
      "step: 524, loss: 1.9112149477005005\n",
      "step: 529, loss: 1.9780768156051636\n",
      "step: 534, loss: 2.585000991821289\n",
      "step: 539, loss: 1.6675970554351807\n",
      "step: 544, loss: 1.908616065979004\n",
      "step: 549, loss: 1.761350154876709\n",
      "step: 554, loss: 2.259594440460205\n",
      "step: 559, loss: 1.978938102722168\n",
      "step: 564, loss: 1.895570158958435\n",
      "step: 569, loss: 1.7688016891479492\n",
      "step: 574, loss: 1.9997361898422241\n",
      "step: 579, loss: 1.7764520645141602\n",
      "step: 584, loss: 1.818061351776123\n",
      "step: 589, loss: 1.8532464504241943\n",
      "step: 594, loss: 1.8336093425750732\n",
      "step: 599, loss: 1.6707355976104736\n",
      "step: 604, loss: 1.5570106506347656\n",
      "step: 609, loss: 1.9545726776123047\n",
      "step: 614, loss: 2.036466121673584\n",
      "step: 619, loss: 1.4341503381729126\n",
      "Checkpoint is saved\n",
      "step: 624, loss: 2.006442070007324\n",
      "step: 629, loss: 1.8085635900497437\n",
      "step: 634, loss: 1.4803335666656494\n",
      "step: 639, loss: 1.7910127639770508\n",
      "step: 644, loss: 1.7855380773544312\n",
      "step: 649, loss: 1.8349120616912842\n",
      "step: 654, loss: 1.7225472927093506\n",
      "step: 659, loss: 1.8535220623016357\n",
      "step: 664, loss: 1.5279676914215088\n",
      "step: 669, loss: 1.5737519264221191\n",
      "step: 674, loss: 1.659403920173645\n",
      "step: 679, loss: 1.6583068370819092\n",
      "step: 684, loss: 1.54319167137146\n",
      "step: 689, loss: 1.3860633373260498\n",
      "step: 694, loss: 1.73223876953125\n",
      "step: 699, loss: 1.6053736209869385\n",
      "step: 704, loss: 1.2669901847839355\n",
      "step: 709, loss: 1.8178550004959106\n",
      "step: 714, loss: 1.3360434770584106\n",
      "step: 719, loss: 1.7273790836334229\n",
      "step: 724, loss: 1.3380341529846191\n",
      "step: 729, loss: 1.365793228149414\n",
      "step: 734, loss: 1.2454893589019775\n",
      "step: 739, loss: 1.9350858926773071\n",
      "step: 744, loss: 1.3873317241668701\n",
      "step: 749, loss: 1.478729248046875\n",
      "step: 754, loss: 1.4778236150741577\n",
      "step: 759, loss: 1.437654972076416\n",
      "step: 764, loss: 1.6286978721618652\n",
      "step: 769, loss: 1.3944305181503296\n",
      "step: 774, loss: 1.2229208946228027\n",
      "step: 779, loss: 1.1794860363006592\n",
      "step: 784, loss: 1.4986982345581055\n",
      "step: 789, loss: 1.7184771299362183\n",
      "step: 794, loss: 1.0884995460510254\n",
      "step: 799, loss: 1.3488192558288574\n",
      "step: 804, loss: 1.250453233718872\n",
      "step: 809, loss: 1.4274333715438843\n",
      "step: 814, loss: 1.2346975803375244\n",
      "step: 819, loss: 1.449026346206665\n",
      "Checkpoint is saved\n",
      "step: 824, loss: 1.4686250686645508\n",
      "step: 829, loss: 1.0641412734985352\n",
      "step: 834, loss: 1.3939261436462402\n",
      "step: 839, loss: 1.3388934135437012\n",
      "step: 844, loss: 1.2178031206130981\n",
      "step: 849, loss: 1.4323991537094116\n",
      "step: 854, loss: 1.5292283296585083\n",
      "step: 859, loss: 1.8497931957244873\n",
      "step: 864, loss: 1.0013036727905273\n",
      "step: 869, loss: 1.3987140655517578\n",
      "step: 874, loss: 1.362718939781189\n",
      "step: 879, loss: 1.2795253992080688\n",
      "step: 884, loss: 1.265308141708374\n",
      "step: 889, loss: 1.1668580770492554\n",
      "step: 894, loss: 1.151951551437378\n",
      "step: 899, loss: 0.9143486022949219\n",
      "step: 904, loss: 1.442476511001587\n",
      "step: 909, loss: 1.2622575759887695\n",
      "step: 914, loss: 1.2688064575195312\n",
      "step: 919, loss: 1.6177589893341064\n",
      "step: 924, loss: 1.0186164379119873\n",
      "step: 929, loss: 1.127061367034912\n",
      "step: 934, loss: 1.2157633304595947\n",
      "step: 939, loss: 1.1101136207580566\n",
      "step: 944, loss: 0.9228793382644653\n",
      "step: 949, loss: 1.218996286392212\n",
      "step: 954, loss: 1.4446241855621338\n",
      "step: 959, loss: 1.351833701133728\n",
      "step: 964, loss: 1.1350724697113037\n",
      "step: 969, loss: 1.1250321865081787\n",
      "step: 974, loss: 1.0258095264434814\n",
      "step: 979, loss: 1.1592693328857422\n",
      "step: 984, loss: 1.2648454904556274\n",
      "step: 989, loss: 1.1180860996246338\n",
      "step: 994, loss: 0.9641096591949463\n",
      "step: 999, loss: 1.0610723495483398\n",
      "Training time for 1000 steps: 1308.9400730133057s\n"
     ]
    }
   ],
   "source": [
    "# let's train the model\n",
    "\n",
    "# we will use this list to plot losses through steps\n",
    "losses = []\n",
    "\n",
    "# save a checkpoint so we can restore the model later \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "print ('------------------TRAINING------------------')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    t = time.time()\n",
    "    for step in range(steps):\n",
    "        feed = feed_dict(X_train, Y_train)\n",
    "            \n",
    "        backward_step(sess, feed)\n",
    "        \n",
    "        if step % 5 == 4 or step == 0:\n",
    "            loss_value = sess.run(loss, feed_dict = feed)\n",
    "            print('step: {}, loss: {}'.format(step, loss_value))\n",
    "            losses.append(loss_value)\n",
    "        \n",
    "        if step % 200 == 19:\n",
    "            saver.save(sess, 'checkpoints/', global_step=step)\n",
    "            print ('Checkpoint is saved')\n",
    "            \n",
    "    print ('Training time for {} steps: {}s'.format(steps, time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAEkCAYAAAChew9BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118d76ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.plot(losses, linewidth = 1)\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Losses')\n",
    "    plt.ylim((0, 12))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "--------------------------------\n",
      "What' s your name\n",
      "Was\n",
      "ist\n",
      "Ihr\n",
      "Namen\n",
      "\n",
      "--------------------------------\n",
      "2.\n",
      "--------------------------------\n",
      "My name is\n",
      "Mein\n",
      "Name\n",
      "ist\n",
      "\n",
      "--------------------------------\n",
      "3.\n",
      "--------------------------------\n",
      "What are you doing\n",
      "Was\n",
      "machst\n",
      "Sie\n",
      "da\n",
      "\n",
      "--------------------------------\n",
      "4.\n",
      "--------------------------------\n",
      "I am reading a book\n",
      "Ich\n",
      "bin\n",
      "ein\n",
      "paar\n",
      "\n",
      "--------------------------------\n",
      "5.\n",
      "--------------------------------\n",
      "How are you\n",
      "Wie\n",
      "geht'\n",
      "s\n",
      "\n",
      "--------------------------------\n",
      "6.\n",
      "--------------------------------\n",
      "I am good\n",
      "Ich\n",
      "bin\n",
      "gut\n",
      "\n",
      "--------------------------------\n",
      "7.\n",
      "--------------------------------\n",
      "Do you speak English\n",
      "WeiÃt\n",
      "du\n",
      "das\n",
      "ist\n",
      "\n",
      "--------------------------------\n",
      "8.\n",
      "--------------------------------\n",
      "What time is it\n",
      "Wie\n",
      "spÃ¤t\n",
      "ist\n",
      "es\n",
      "\n",
      "--------------------------------\n",
      "9.\n",
      "--------------------------------\n",
      "Hi\n",
      "Hi\n",
      "\n",
      "--------------------------------\n",
      "10.\n",
      "--------------------------------\n",
      "Goodbye\n",
      "Wiedersehen\n",
      "Wiedersehen\n",
      "\n",
      "--------------------------------\n",
      "11.\n",
      "--------------------------------\n",
      "Yes\n",
      "Ja\n",
      "\n",
      "--------------------------------\n",
      "12.\n",
      "--------------------------------\n",
      "No\n",
      "Nicht\n",
      "\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# let's test the model\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    # placeholders\n",
    "    encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "    decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "    # output projection\n",
    "    size = 512\n",
    "    w_t = tf.get_variable('proj_w', [de_vocab_size, size], tf.float32)\n",
    "    b = tf.get_variable('proj_b', [de_vocab_size], tf.float32)\n",
    "    w = tf.transpose(w_t)\n",
    "    output_projection = (w, b)\n",
    "    \n",
    "    # change the model so that output at time t can be fed as input at time t+1\n",
    "    outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                                encoder_inputs,\n",
    "                                                decoder_inputs,\n",
    "                                                tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                                num_encoder_symbols = en_vocab_size,\n",
    "                                                num_decoder_symbols = de_vocab_size,\n",
    "                                                embedding_size = 100,\n",
    "                                                feed_previous = True, # <-----this is changed----->\n",
    "                                                output_projection = output_projection,\n",
    "                                                dtype = tf.float32)\n",
    "    \n",
    "    # ops for projecting outputs\n",
    "    outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "    # let's translate these sentences     \n",
    "    en_sentences = [\"What' s your name\", 'My name is', 'What are you doing', 'I am reading a book',\\\n",
    "                    'How are you', 'I am good', 'Do you speak English', 'What time is it', 'Hi', 'Goodbye', 'Yes', 'No']\n",
    "    en_sentences_encoded = [[en_word2idx.get(word, 0) for word in en_sentence.split()] for en_sentence in en_sentences]\n",
    "    \n",
    "    # padding to fit encoder input\n",
    "    for i in range(len(en_sentences_encoded)):\n",
    "        en_sentences_encoded[i] += (15 - len(en_sentences_encoded[i])) * [en_word2idx['<pad>']]\n",
    "    \n",
    "    # restore all variables - use the last checkpoint saved\n",
    "    saver = tf.train.Saver()\n",
    "    path = tf.train.latest_checkpoint('checkpoints')\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # restore\n",
    "        saver.restore(sess, path)\n",
    "        \n",
    "        # feed data into placeholders\n",
    "        feed = {}\n",
    "        for i in range(input_seq_len):\n",
    "            feed[encoder_inputs[i].name] = np.array([en_sentences_encoded[j][i] for j in range(len(en_sentences_encoded))], dtype = np.int32)\n",
    "            \n",
    "        feed[decoder_inputs[0].name] = np.array([de_word2idx['<go>']] * len(en_sentences_encoded), dtype = np.int32)\n",
    "        \n",
    "        # translate\n",
    "        output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "        \n",
    "        # decode seq.\n",
    "        for i in range(len(en_sentences_encoded)):\n",
    "            print ('{}.\\n--------------------------------'.format(i+1))\n",
    "            ouput_seq = [output_sequences[j][i] for j in range(output_seq_len)]\n",
    "            #decode output sequence\n",
    "            words = decode_output(ouput_seq)\n",
    "        \n",
    "            print (en_sentences[i])\n",
    "            for i in range(len(words)):\n",
    "                if words[i] not in ['<eos>', '<pad>', '<go>']:\n",
    "                    print (words[i],)\n",
    "            \n",
    "            print ('\\n--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This model can be improved by using more training steps, better dataset or even with better selection of hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
