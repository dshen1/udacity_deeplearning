{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f) #,encoding='latin1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read all data into variables \n",
    "X,Y,X_max_length,Y_max_length,en_int_to_vocab,en_vocab_to_int,cn_int_to_vocab,cn_vocab_to_int = read_dataset('cn2en.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence in English - encoded: [953, 427, 91, 50, 4, 48180, 7362, 5, 4]\n",
      "Sentence in Chinese - encoded: [12, 175, 5, 564, 526, 127, 443, 394, 30, 1084, 366]\n",
      "Decoded:\n",
      "------------------------\n",
      " Keep fucking going !  Controlled aggression . \n",
      " 他 妈 的 继 续 啊 控 制 好 攻 击\n"
     ]
    }
   ],
   "source": [
    "# inspect data\n",
    "print ('Sentence in English - encoded:', X[2])\n",
    "print ('Sentence in Chinese - encoded:', Y[2])\n",
    "print ('Decoded:\\n------------------------')\n",
    "\n",
    "s=\"\"\n",
    "for i in range(len(X[2])):\n",
    "    s = s + \" \" + en_int_to_vocab[X[2][i]]\n",
    "print(s)\n",
    "\n",
    "s=\"\"\n",
    "for i in range(len(Y[2])):\n",
    "    s = s + \" \" + cn_int_to_vocab[Y[2][i]]\n",
    "print (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data padding\n",
    "\n",
    "def data_padding(x, y, length):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i] + (length - len(x[i])) * [en_vocab_to_int['<pad>']]\n",
    "        y[i] = [cn_vocab_to_int['<go>']] + y[i] + [cn_vocab_to_int['<eos>']] + (length-len(y[i])) * [cn_vocab_to_int['<pad>']]\n",
    "\n",
    "input_length = min(max(X_max_length,Y_max_length),50)\n",
    "        \n",
    "data_padding(X, Y,input_length)\n",
    "\n",
    "# data splitting\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)\n",
    "\n",
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a model\n",
    "\n",
    "input_seq_len = input_length\n",
    "output_seq_len = input_length+2\n",
    "en_vocab_size = len(en_vocab_to_int)# + 2 # + <pad>, <ukn>\n",
    "cn_vocab_size = len(cn_vocab_to_int)# + 4 # + <pad>, <ukn>, <eos>, <go>\n",
    "\n",
    "# placeholders\n",
    "encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "targets = [decoder_inputs[i+1] for i in range(output_seq_len-1)]\n",
    "targets.append(tf.placeholder(dtype = tf.int32, shape = [None], name = 'last_target')) ## add last, to make it the same as decode input\n",
    "target_weights = [tf.placeholder(dtype = tf.float32, shape = [None], name = 'target_w{}'.format(i)) for i in range(output_seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output projection\n",
    "size = 512\n",
    "w_t = tf.get_variable('proj_w', [cn_vocab_size, size], tf.float32)\n",
    "b = tf.get_variable('proj_b', [cn_vocab_size], tf.float32)\n",
    "w = tf.transpose(w_t)\n",
    "output_projection = (w, b)\n",
    "\n",
    "outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                            encoder_inputs,\n",
    "                                            decoder_inputs,\n",
    "                                            tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                            num_encoder_symbols = en_vocab_size,\n",
    "                                            num_decoder_symbols = cn_vocab_size,\n",
    "                                            embedding_size = 100,\n",
    "                                            feed_previous = False,\n",
    "                                            output_projection = output_projection,\n",
    "                                            dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define our loss function\n",
    "\n",
    "# sampled softmax loss - returns: A batch_size 1-D tensor of per-example sampled softmax losses\n",
    "def sampled_loss(labels, logits):\n",
    "    return tf.nn.sampled_softmax_loss(\n",
    "                        weights = w_t,\n",
    "                        biases = b,\n",
    "                        labels = tf.reshape(labels, [-1, 1]),\n",
    "                        inputs = logits,\n",
    "                        num_sampled = 512,\n",
    "                        num_classes = cn_vocab_size)\n",
    "\n",
    "# Weighted cross-entropy loss for a sequence of logits\n",
    "loss = tf.contrib.legacy_seq2seq.sequence_loss(outputs, targets, target_weights, softmax_loss_function = sampled_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's define some helper functions\n",
    "\n",
    "# simple softmax function\n",
    "def softmax(x):\n",
    "    n = np.max(x)\n",
    "    e_x = np.exp(x - n)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# feed data into placeholders\n",
    "def feed_dict(x, y, batch_size = 64):\n",
    "    feed = {}\n",
    "    idxes = np.random.choice(len(x), size = batch_size, replace = False)\n",
    "    for i in range(input_seq_len):\n",
    "        feed[encoder_inputs[i].name] = np.array([x[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    for i in range(output_seq_len):\n",
    "        feed[decoder_inputs[i].name] = np.array([y[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    feed[targets[len(targets)-1].name] = np.full(shape = [batch_size], fill_value = cn_vocab_to_int['<pad>'], dtype = np.int32)\n",
    "    \n",
    "    for i in range(output_seq_len-1):\n",
    "        batch_weights = np.ones(batch_size, dtype = np.float32)\n",
    "        target = feed[decoder_inputs[i+1].name]\n",
    "        for j in range(batch_size):\n",
    "            if target[j] == cn_vocab_to_int['<pad>']:\n",
    "                batch_weights[j] = 0.0\n",
    "        feed[target_weights[i].name] = batch_weights\n",
    "        \n",
    "    feed[target_weights[output_seq_len-1].name] = np.zeros(batch_size, dtype = np.float32)\n",
    "    \n",
    "    return feed\n",
    "\n",
    "# decode output sequence\n",
    "def decode_output(output_seq):\n",
    "    words = [cn_int_to_vocab[idx] for idx in output_seq]\n",
    "    return words\n",
    "             \n",
    "# def decode_output(output_seq):\n",
    "#     words = []\n",
    "#     for i in range(output_seq_len):\n",
    "#         smax = softmax(output_seq[i])\n",
    "#         idx = np.argmax(smax)\n",
    "#         words.append(cn_vocab_to_int[idx])\n",
    "#     return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ops and hyperparameters\n",
    "learning_rate = 5e-3\n",
    "batch_size = 64\n",
    "steps = 10000\n",
    "\n",
    "# ops for projecting outputs\n",
    "outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "# training op\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# init op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# forward step\n",
    "def forward_step(sess, feed):\n",
    "    output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "    return output_sequences\n",
    "\n",
    "# training step\n",
    "def backward_step(sess, feed):\n",
    "    sess.run(optimizer, feed_dict = feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TRAINING------------------\n",
      "step: 0, loss: 8.049732208251953\n",
      "Checkpoint is saved\n",
      "step: 200, loss: 5.007501602172852\n",
      "step: 400, loss: 3.7146365642547607\n",
      "step: 600, loss: 3.265096664428711\n",
      "step: 800, loss: 2.882694721221924\n",
      "step: 1000, loss: 2.8592934608459473\n",
      "Checkpoint is saved\n",
      "step: 1200, loss: 2.3907723426818848\n",
      "step: 1400, loss: 2.3186521530151367\n",
      "step: 1600, loss: 2.5496885776519775\n",
      "step: 1800, loss: 2.2948598861694336\n",
      "step: 2000, loss: 2.4860246181488037\n",
      "Checkpoint is saved\n",
      "step: 2200, loss: 2.0967469215393066\n",
      "step: 2400, loss: 2.227423667907715\n",
      "step: 2600, loss: 2.133627414703369\n",
      "step: 2800, loss: 2.00405216217041\n",
      "step: 3000, loss: 2.1269402503967285\n",
      "Checkpoint is saved\n",
      "step: 3200, loss: 1.748936653137207\n",
      "step: 3400, loss: 1.9100935459136963\n",
      "step: 3600, loss: 1.874370813369751\n",
      "step: 3800, loss: 1.7887767553329468\n",
      "step: 4000, loss: 1.7585563659667969\n",
      "Checkpoint is saved\n",
      "step: 4200, loss: 1.7264553308486938\n",
      "step: 4400, loss: 1.8747832775115967\n",
      "step: 4600, loss: 1.7500547170639038\n",
      "step: 4800, loss: 1.7206642627716064\n",
      "step: 5000, loss: 1.7342545986175537\n",
      "Checkpoint is saved\n",
      "step: 5200, loss: 1.8760762214660645\n",
      "step: 5400, loss: 1.8077682256698608\n",
      "step: 5600, loss: 1.7085745334625244\n",
      "step: 5800, loss: 1.805045247077942\n",
      "step: 6000, loss: 1.6061460971832275\n",
      "Checkpoint is saved\n",
      "step: 6200, loss: 1.7462029457092285\n",
      "step: 6400, loss: 1.6030488014221191\n",
      "step: 6600, loss: 1.5591936111450195\n",
      "step: 6800, loss: 1.710435390472412\n",
      "step: 7000, loss: 1.681572675704956\n",
      "Checkpoint is saved\n",
      "step: 7200, loss: 1.4030811786651611\n",
      "step: 7400, loss: 1.731742262840271\n",
      "step: 7600, loss: 1.3607401847839355\n",
      "step: 7800, loss: 1.7509902715682983\n",
      "step: 8000, loss: 1.6047265529632568\n",
      "Checkpoint is saved\n",
      "step: 8200, loss: 1.520925760269165\n",
      "step: 8400, loss: 1.5247352123260498\n",
      "step: 8600, loss: 1.5928452014923096\n",
      "step: 8800, loss: 1.5684576034545898\n",
      "step: 9000, loss: 1.5547510385513306\n",
      "Checkpoint is saved\n",
      "step: 9200, loss: 1.6197686195373535\n",
      "step: 9400, loss: 1.58564293384552\n",
      "step: 9600, loss: 1.3976271152496338\n",
      "step: 9800, loss: 1.5904048681259155\n",
      "Training time for 10000 steps: 3435.2027382850647s\n"
     ]
    }
   ],
   "source": [
    "# let's train the model\n",
    "\n",
    "# we will use this list to plot losses through steps\n",
    "losses = []\n",
    "\n",
    "# save a checkpoint so we can restore the model later \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "print ('------------------TRAINING------------------')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    t = time.time()\n",
    "    for step in range(steps):\n",
    "        feed = feed_dict(X_train, Y_train)\n",
    "            \n",
    "        backward_step(sess, feed)\n",
    "        \n",
    "        if step % 200 == 0 or step == 0:\n",
    "            loss_value = sess.run(loss, feed_dict = feed)\n",
    "            print('step: {}, loss: {}'.format(step, loss_value))\n",
    "            losses.append(loss_value)\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            saver.save(sess, 'checkpoints/', global_step=step)\n",
    "            print ('Checkpoint is saved')\n",
    "            \n",
    "    print ('Training time for {} steps: {}s'.format(steps, time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAEkCAYAAAChew9BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpIthhgREckWQ4yIiGSLIUZERLL1/xehYWD/T9sOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a46525da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.plot(losses, linewidth = 1)\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Losses')\n",
    "    plt.ylim((0, 12))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "--------------------------------\n",
      "What' s your name\n",
      "你叫我的名叫\n",
      "\n",
      "--------------------------------\n",
      "2.\n",
      "--------------------------------\n",
      "what is going on? I have no idea.\n",
      "我不是什么意思\n",
      "\n",
      "--------------------------------\n",
      "3.\n",
      "--------------------------------\n",
      "My name is\n",
      "我的名叫\n",
      "\n",
      "--------------------------------\n",
      "4.\n",
      "--------------------------------\n",
      "What are you doing\n",
      "你在干什么\n",
      "\n",
      "--------------------------------\n",
      "5.\n",
      "--------------------------------\n",
      "I am reading a book\n",
      "我很读急\n",
      "\n",
      "--------------------------------\n",
      "6.\n",
      "--------------------------------\n",
      "How are you?\n",
      "你们怎么样\n",
      "\n",
      "--------------------------------\n",
      "7.\n",
      "--------------------------------\n",
      "I am good\n",
      "我很好\n",
      "\n",
      "--------------------------------\n",
      "8.\n",
      "--------------------------------\n",
      "Do you speak English\n",
      "你说英雄\n",
      "\n",
      "--------------------------------\n",
      "9.\n",
      "--------------------------------\n",
      "What time is it\n",
      "我们的时间\n",
      "\n",
      "--------------------------------\n",
      "10.\n",
      "--------------------------------\n",
      "Hi\n",
      "你们\n",
      "\n",
      "--------------------------------\n",
      "11.\n",
      "--------------------------------\n",
      "Goodbye\n",
      "你们的情况\n",
      "\n",
      "--------------------------------\n",
      "12.\n",
      "--------------------------------\n",
      "Yes\n",
      "是的\n",
      "\n",
      "--------------------------------\n",
      "13.\n",
      "--------------------------------\n",
      "No\n",
      "不是你\n",
      "\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# let's test the model\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    # placeholders\n",
    "    encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "    decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "    # output projection\n",
    "    size = 512\n",
    "    w_t = tf.get_variable('proj_w', [cn_vocab_size, size], tf.float32)\n",
    "    b = tf.get_variable('proj_b', [cn_vocab_size], tf.float32)\n",
    "    w = tf.transpose(w_t)\n",
    "    output_projection = (w, b)\n",
    "    \n",
    "    # change the model so that output at time t can be fed as input at time t+1\n",
    "    outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                                encoder_inputs,\n",
    "                                                decoder_inputs,\n",
    "                                                tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                                num_encoder_symbols = en_vocab_size,\n",
    "                                                num_decoder_symbols = cn_vocab_size,\n",
    "                                                embedding_size = 100,\n",
    "                                                feed_previous = True, # <-----this is changed----->\n",
    "                                                output_projection = output_projection,\n",
    "                                                dtype = tf.float32)\n",
    "    \n",
    "    # ops for projecting outputs\n",
    "    outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "    # let's translate these sentences     \n",
    "    en_sentences = [\"What' s your name\", 'what is going on? I have no idea.','My name is', 'What are you doing', 'I am reading a book',\\\n",
    "                    'How are you?', 'I am good', 'Do you speak English', 'What time is it', 'Hi', 'Goodbye', 'Yes', 'No']\n",
    "    en_sentences_encoded = [[en_vocab_to_int.get(word, 0) for word in en_sentence.split()] for en_sentence in en_sentences]\n",
    "\n",
    "    # padding to fit encoder input\n",
    "    for i in range(len(en_sentences_encoded)):\n",
    "        en_sentences_encoded[i] += (input_seq_len - len(en_sentences_encoded[i])) * [en_vocab_to_int['<pad>']]\n",
    "    \n",
    "    # restore all variables - use the last checkpoint saved\n",
    "    saver = tf.train.Saver()\n",
    "    path = tf.train.latest_checkpoint('checkpoints')\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # restore\n",
    "        saver.restore(sess, path)\n",
    "        \n",
    "        # feed data into placeholders\n",
    "        feed = {}\n",
    "        for i in range(input_seq_len):\n",
    "            feed[encoder_inputs[i].name] = np.array([en_sentences_encoded[j][i] for j in range(len(en_sentences_encoded))], dtype = np.int32)\n",
    "            \n",
    "        feed[decoder_inputs[0].name] = np.array([cn_vocab_to_int['<go>']] * len(en_sentences_encoded), dtype = np.int32)\n",
    "        \n",
    "        # translate\n",
    "        output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "        output_predicts = np.argmax(np.array(output_sequences).transpose(1,0,2),2)\n",
    "        \n",
    "        # decode seq.\n",
    "        for i in range(len(output_predicts)):\n",
    "            print ('{}.\\n--------------------------------'.format(i+1))\n",
    "            ouput_seq = output_predicts[i,:]\n",
    "            #decode output sequence\n",
    "            words = decode_output(ouput_seq)\n",
    "        \n",
    "            print (en_sentences[i])\n",
    "            chinese_words =''\n",
    "            for i in range(len(words)):\n",
    "                if words[i] not in ['<eos>', '<pad>', '<go>']:\n",
    "                    chinese_words+=words[i]\n",
    "            print(chinese_words)\n",
    "            print ('\\n--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This model can be improved by using more training steps, better dataset or even with better selection of hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
