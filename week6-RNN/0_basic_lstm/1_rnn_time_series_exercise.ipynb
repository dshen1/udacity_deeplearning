{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for time series - exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*UkI9za9zTR-HL8uM15Wmzw.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*UkI9za9zTR-HL8uM15Wmzw.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Set up hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "total_series_length = 50000      \n",
    "truncated_backprop_length = 15  ## sequence length \n",
    "state_size = 4                  ## number of neuros in hidden layer\n",
    "num_classes = 2 \n",
    "echo_step = 3                   ## how many steps you want to shift \n",
    "batch_size = 5\n",
    "num_batches = total_series_length//(batch_size*truncated_backprop_length)  # number of batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. generate some test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData(total_series_length):\n",
    "    x = np.array(np.random.choice(2,total_series_length,p=[0.5,0.5]))  ## random choose 0 and 1 for 50000 times\n",
    "    y = np.roll(x,echo_step)                          ## shift the data to the right by echo_steps \n",
    "    y[0:echo_step] = 0 \n",
    "    x = x.reshape((batch_size,-1))                    ## make them into different batches \n",
    "    y= y.reshape((batch_size,-1))                     ## make them into different batches\n",
    "    \n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 1, 0, 1],\n",
       "        [1, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 1, 1, ..., 1, 0, 1],\n",
       "        [1, 0, 0, ..., 1, 0, 0]]), array([[0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 1],\n",
       "        [1, 0, 1, ..., 1, 0, 1],\n",
       "        [1, 0, 0, ..., 1, 0, 1],\n",
       "        [1, 0, 1, ..., 1, 1, 1]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generateData(total_series_length)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# input and output data\n",
    "batchX_placeholder = tf.placeholder(tf.float32,[batch_size,truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32,[batch_size,truncated_backprop_length])\n",
    "\n",
    "# this is RNN state \n",
    "init_state = tf.placeholder(tf.float32,[batch_size,state_size])\n",
    "\n",
    "# weights and biases 1  \n",
    "W = tf.Variable(np.random.rand(state_size+1,state_size),dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((1,state_size)),dtype=tf.float32)\n",
    "# weights and biases 2  \n",
    "W2 = tf.Variable(np.random.rand(state_size,num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5), Dimension(15)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchX_placeholder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*n45uYnAfTDrBvG87J-poCA.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*n45uYnAfTDrBvG87J-poCA.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## unpack batch matrix into 1 dimensional array\n",
    "inputs_series = tf.unstack(batchX_placeholder, axis=1)   ## basically sliced each column into a sequence of arraies\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)   ## basically sliced each column into a sequence of arraies\n",
    "# we do this because we need to feed data into rnn as sequence, \n",
    "# we feed in one column at a time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack:0' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:1' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:2' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:3' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:4' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:5' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:6' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:7' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:8' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:9' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:10' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:11' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:12' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:13' shape=(5,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:14' shape=(5,) dtype=float32>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## take a look at how our inputs get transformed\n",
    "inputs_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "# stat placeholder \n",
    "\n",
    "current_state = init_state\n",
    "state_series = []\n",
    "\n",
    "for current_input in inputs_series:\n",
    "    current_input = tf.reshape(current_input,[batch_size,1])\n",
    "    input_and_state_concatenated = tf.concat([current_input, current_state],1)\n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)\n",
    "    state_series.append(next_state)\n",
    "    current_state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*fdwNNJ5UOE3Sx0R_Cyfmyg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*fdwNNJ5UOE3Sx0R_Cyfmyg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## calculat loss and minimize it \n",
    "#second part of forward pass\n",
    "#logits short for logistic transform\n",
    "logits_series = [tf.matmul(state,W2) + b2 for state in state_series]\n",
    "#apply softmax nonlinearity for output probability\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "# measure loss, calculate softmax again on logits, then compute cross entropy\n",
    "# softmax cross entropy will apply softmax by it self\n",
    "# here, our lables are not onehot encoded, we use sparse_softmax_cross_entropy\n",
    "# if our lables are one hot encoded, we use softmax_cross_entropy\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for \n",
    "          logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "## optimizer \n",
    "## great paper http://seed.ucsd.edu/mediawiki/images/6/6a/Adagrad.pdf\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "#visualizer\n",
    "###############\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca313e3e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Loss 0.761303\n",
      "New data, epoch 1\n",
      "Step 0 Loss 0.578917\n",
      "New data, epoch 2\n",
      "Step 0 Loss 0.120799\n",
      "New data, epoch 3\n",
      "Step 0 Loss 0.179847\n",
      "New data, epoch 4\n",
      "Step 0 Loss 0.161916\n",
      "New data, epoch 5\n",
      "Step 0 Loss 0.16888\n",
      "New data, epoch 6\n",
      "Step 0 Loss 0.192469\n",
      "New data, epoch 7\n",
      "Step 0 Loss 0.12838\n",
      "New data, epoch 8\n",
      "Step 0 Loss 0.118951\n",
      "New data, epoch 9\n",
      "Step 0 Loss 0.132007\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca30f5c4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #interactive mode\n",
    "    plt.ion()\n",
    "    #initialize the figure\n",
    "    plt.figure()\n",
    "    #show the graph\n",
    "    plt.show()\n",
    "    #to show the loss decrease\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs): ## loop through all batches\n",
    "        x,y = generateData(total_series_length)\n",
    "        _current_state = np.zeros((batch_size,state_size))  ## initial state, set to be all 0s \n",
    "                                                            ## it was a place holder, set up earlier before\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "        for batch_idx  in range(num_batches):\n",
    "            #starting and ending point per batch\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "            \n",
    "            _total_loss,_train_step,_current_state,_predictions_series = sess.run(\n",
    "                [total_loss,train_step,current_state,predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY,\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "            \n",
    "            loss_list.append(_total_loss)\n",
    "            \n",
    "            if batch_idx%1000 ==0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
